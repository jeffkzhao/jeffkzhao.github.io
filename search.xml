<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[2 反向传播]]></title>
    <url>%2F2017%2F09%2F05%2FbackPropagation%2F</url>
    <content type="text"><![CDATA[BackPropagation这部分讲如何高效地计算神经网络中的梯度。 链式法则多元复合函数的求导公式利用了偏导数的链式法则chain rule，注意下面偏导数的表示形式。 BackPropagation看一下我们要计算的梯度形式，每一个训练样本的损失函数为$l^n$，最终的损失函数$L(\theta )$ 是所有训练样本的summation。目标是求对不同$w$的梯度： 因为神经网络有很多层，那么我们就必须用chain rule一步一步的计算。$L(\theta )$是$l^n$的summation，所以我们只关注单个$l^i$就可以了。先尝试从前往后计算，考虑二维的简单网络，我们求偏导数$\frac{\partial l}{\partial w}$: $\frac{\partial z}{\partial w}$ 很明显，就是对应的输入值，那么我们只需要将不同层neurons的输出值计算出来就可以了。 重点在第二部分$\frac{\partial l}{\partial z}$ ，我们再用一次chain rull： $\frac{\partial a}{\partial z} = {\sigma}’ (z)$，这个也好计算。接下来我们就要计算$\frac{\partial l}{\partial a}$。这里记住$l$是神经网络最后计算结果$y$的函数，还是需要用chain rull计算偏导数: $\frac{\partial l}{\partial z}$ 是下一层 $\frac{\partial l}{\partial z}$的加权summation。我们就需要这样递归的一步一步计算下去，直到输出层，才能得到该层的 $\frac{\partial l}{\partial z}$。 最后一层的 $\frac{\partial l}{\partial z} = \frac{\partial l}{\partial y} \frac{\partial y}{\partial z}$，这两项都是可以直接计算出来的，递归终止。 $\frac{\partial l}{\partial z}$依赖于后层的 $\frac{\partial l}{\partial z}$。显然我们应该从最后一层反过来计算 $\frac{\partial l}{\partial z}$，因为从后往前计算所有的 $\frac{\partial l}{\partial z}$简单直观多了，这就是backpropagation。总结一下，用gradient descent优化神经网络，重点是如何计算梯度$\frac{\partial l}{\partial w}$。使用train rule分解为两部分$\frac{\partial z}{\partial w} \times \frac{\partial l}{\partial z}$ ：前半部分也就是前一层的神经元输出（第一层就是输入值）在forward pass 阶段计算；后一部分从最后一层开始，逐层往前计算$\frac{\partial l}{\partial z}$： 具体的计算流程如下图，上标表示层，下标单数字表示该层排列号，双数字，如$w^l_{ij}$, $i$表示l层中的排列号，$j$表示前一层$l -1$层的排列号 ： 稍复杂的地方是bp中的这个迭代过程：$\frac{\partial C}{\partial z^l} = \frac{\partial a^l}{\partial z^l} \frac{\partial C}{\partial a^l} = {\sigma}’ (z^l)\frac{\partial C}{\partial a^l} = {\sigma}’ (z^l) \frac{\partial z^{l + 1}}{\partial a^l}\frac{\partial C}{\partial z^{l + 1}} = {\sigma}’ (z^l) \left({W^{l + 1}} \right) ^\mathrm{\top} \frac{\partial C}{\partial z^{l + 1}} $. 最后这个组合$\left( {W^{l + 1}} \right) ^\mathrm{\top} \frac{\partial C}{\partial z^{l + 1}}$实际上就是前面讲到的下一层权重与偏导数的summation，只不过这地方用矩阵乘法的方式计算。转置是因为我们定义的$W$下一层作为横轴，所有要转一下。最后得到的$\frac{\partial C}{\partial z^l}$是一个vector。 BP的计算图解释还可以用计算图的方法解释BP的过程。计算图computational Graph是一种描述function的形式，node代表变量(scalar，vector，tensor…), edge代表操作，如函数$e = (a+b) \times (b + 1)$用计算图表示： 全联接网络的计算图表示我们以一个两层神经网络为例： 梯度的BP计算过程我们使用计算图来完成： 我们需要从最后一层开始逐层往前计算偏导数。vector$\boldsymbol{y}$对vector$\boldsymbol{x}$的偏导数是一个Jacobian Matrix，高度是y的维度，宽度是x的维度。下面还是以MNIST计算为例。- 求$\frac{\partial C }{\partial y}$, $C$采用corss entropy，即$C = -log y_r$。由于$C$是一个scalar，所以结果是大小为 $1 \times len(y)$的matrix。$r$是真实值$\hat{y}$中1的位置，该位置$\frac{\partial C }{\partial y_{r = i} }= 0$，其他$\frac{\partial C }{\partial y_i }= 0$: 接着求$\frac{\partial y }{\partial z^2}$。这里激活函数使用sigmod。$\frac{\partial y }{\partial z^2}$结果是一个Jacobian Matrix，由于y就是该层neurons的输出，每个y对应一个neuron，即$y_i = \sigma (z^2_i)$。那么这个matrix只用$i = j$ 处才值，其他地方偏导为0，既是一个diagonal matrix： 注意若激活函数是softmax，就不是diagonal matrix了，因为每个z都对y由贡献。 - 接下来就是求$\frac{\partial z^2 }{\partial a^1}$,同样也是一个Jacobian matrix，偏导就是对应的权重值，整个matrix就是$W^2$: 求$\frac{\partial z^2 }{\partial W^2}$，$W^2$是一个matrix，结构如下： $z^l_i$只与计算该值的$w^{l}_{ij}$相关，如下图，所以最后的结果是一个类diagonal mtrix,值为$a^{l -1}$ : 最后我们要求$\frac{\partial C }{\partial W^1}$，就是将路径上的所有偏导乘起来就可以了，注意最后结果的维度, 高度为1，宽度为$m \times n$: 计算图的结果和采用BP是一致的。计算图貌似只使用Backforward过程，但$a$的计算都需要forward progress处理。]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>back-propagation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1 深度前馈网络]]></title>
    <url>%2F2017%2F09%2F05%2FdeepLearning%2F</url>
    <content type="text"><![CDATA[Fully Connect Feedforward Network 不同的连接方式构成不同的网络结构。 所有的neurons神经节点中的权重$w$和偏置$b$就是Network parameter $\boldsymbol{\theta}$ .fully connect是指全连接：前一层m个neurons与后一层n个neurons都有连接，连接数为$m \times n$。Feedforward：neurons影响下层neurons，而不会返回影响上层节点。 Deep = Many Hidden Layers: 计算一个神经网络实际上起到是一个函数作用$\mathbb{R}^m \to \mathbb{R}^n $。输入层进过每一层的计算，最终得到最后的结果。 计算过程中，会用到大量的矩阵计算。*如果输入层是m维，下一层neurons的个数是n，那么这个矩阵就是$n \times m$矩阵。矩阵是线性变换：列$j$代表对输入$a_j$的线性变换，也就是$a_j$与下一层neurons连接的权重组成。矩阵的行$i$与下一层$z_i$对应：$z_i = \sum w_{i}x_* $。如下图，矩阵是一个$2 \times 2$的矩阵： 当经过所有层的运算，实际上就是一个叠加的过程，可以使用并行计算加速矩阵操作： 当输出为多类时，我们可以使用Softmax： 使用神经网络的好处是特征工程不是那么重要了：DL本身就是一个特征变换的过程，另外经常我们不知道哪个特征更好。我们需要决定的是网络结构是什么样的：多少层，每层多少个neurons（经验，尝试），激活函数等。网络结构就决定了我们的function set, 下一步就是怎么衡量function的好坏。我们还是用交叉熵： 和所有的机器学习模型一样，为了找到合适参数组合，最后我们就要最小化所有训练集上的交叉熵之和： 这个最优化问题还是采用梯度下降法去求： 这里梯度的计算就是重点，如何高效的求梯度？就要用到BP算法。]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>deep-learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10 机器学习系统设计]]></title>
    <url>%2F2017%2F09%2F04%2FmlSystemDesign%2F</url>
    <content type="text"><![CDATA[如何设计一个机器学习系统?一个好的系统其实需要考虑很多的东西,不单纯是模型的问题:如垃圾邮件系统: 收集更多的样本 基于邮件的路由信息开发一系列复杂的特征: 群发邮件 基于邮件的正文信息开发一系列复杂的特征，包括考虑截词的处理:内容检测 为探测刻意的拼写错误（把watch写成w4tch）开发复杂的算法 误差分析（ERROR ANALYSIS）误差分析可以帮助我们系统化地选择该做什么.构建一个学习算法的推荐方法为： 从一个简单的能快速实现的算法开始，实现该算法并用交叉验证集数据测试这个算法. 绘制学习曲线，决定: 增加更多数据: 过拟合/high variance； 添加更多特征: 欠拟合/high bias，还是其他选择； 进行误差分析：人工检查交叉验证集中我们算法中产生预测误差的实例，看看这些实例是否有某种系统化的趋势； 误差分析可能并不总能帮助我们，我们还需要尝试不同的模型来比较。 类偏斜的误差度量（ERROR METRICS FOR SKEWED CLASSES）skewed classespositive的实例很少，只用准确率去判断无法正确反映分类器的实例：若negative样本为99%，那么即使把所有样本全部预测为negative，从整体样本来说准确率还可以达到99%!!两个度量: 准确率Precision： 预测正确的个数/预测总数； 覆盖率Recall： 预测正确的个数/实际样本中的总数；在现实中，根据实际需要，取舍两者的比例。另外，我们可以用F1值／F1 score 来自动均衡两者:$$F1 = 2 \times \frac{PR}{p+ R}$$ 机器学习的数据回到上面的问题，当效果不好的时候，我们是要增加样本数据，还是考虑修改模型，抑或是换一个模型？也可以这么想：在这些特征面前，一个真人专家是否能有信心地预测结果？若可以，而我们的模型又high variance，代价函数也小，那么就可以考虑增加样本，因为模型过拟合了。过拟合其实说明一点：该模型能够描绘出特征信息，可以考虑增加样本，减少特征数的方法。若此时是high bias，那增加样本也无能为力了。 我们希望我们的算法低偏倚，低偏差： 选择更多的特征来降低偏倚； 再通过增加数据量来降低偏差。]]></content>
      <categories>
        <category>吴恩达Coursera笔记</category>
      </categories>
      <tags>
        <tag>machine-learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[9 机器学习应用建议]]></title>
    <url>%2F2017%2F09%2F04%2Fsuggestion%2F</url>
    <content type="text"><![CDATA[优化选择回归模型预测结果很差,怎么办？ 1 获得更多的训练实例; 2 尝试减少特征的数量 –减少过拟合; 3尝试获得更多的特征–欠拟合，有效的特征数偏少; 4 尝试增加二项式特征– 如 $x_1^2,x_2^2, x_1*x_2$ 模型选择问题; 5 尝试减少归一化程度$\lambda$ ; 6 尝试增加归一化程度$\lambda$ ;这些办法也不是随机选择的，需要运用一些分析，帮助你知道问题所在; 假设评估 evaluating hypothesis 评估训练得到的假设Hypothesis; 数据分成训练集和测试集，通常用70%的数据作为训练集，用剩下30%的数据作为测试集; 训练集和测试集均要含有各种类型的数据; 通常要对数据进行“洗牌”：randomly shuffle，保证数据的均匀分布，然后再分成训练集和测试集。 测试集评估对测试集运用该模型，我们有两种方式计算误差： 对于线性回归模型，我们利用测试集数据计算代价函数J ; 对于逻辑回归模型，我们除了可以利用测试数据集来计算代价函数外： 还可以计算错误分类的比率，对于每一个测试集实例，计算： 交叉验证-模型选择 我们有多个相类似的模型，如何选择出”最好”的模型？ 假设我们要在10个不同次数的二项式模型之间进行选择： 越高次数的二项式模型越能够适应我们的训练数据集，但并不代表着能推广至一般情况，我们应该选择一个更能适应一般情况的模型：泛化。 步骤使用交叉验证集来帮助选择模型： 1训练集拆分： 使用60%的数据作为训练集; 使用39%的数据作为交叉验证集; 使用39%的数据作为测试集; 2 使用训练集训练出10个模型; 3 用10个模型分别对交叉验证集计算得出交叉验证误差（代价函数的值）; 4 选取代价函数值最小的模型; 5 用步骤4中选出的模型对测试集计算得出推广误差（代价函数的值）; 偏倚和偏差诊断（DIAGNOSIS BIAS VS. VARIANCE） bias: 偏倚，与实际的线路偏差了-欠拟合; variance/偏差：方差，过拟合造成曲线过于频繁上下波动，方差也就大；我们想让曲线更平滑一些，所以说过拟合的情况为high variance。 诊断将训练集和交叉验证集的代价函数误差与多项式的次数绘制在同一张图表上来帮助分析： 1 d较小时， 训练集和交叉验证集误差近似，且误差均比较大，随着d增加而同时减少; 2 当d增大时，交叉验证集误差呈现先减小后增大的趋势，转折点是我们的模型开始过拟合训练数据集的时候。 3 d增大， 训练集误差一直减少，直到过拟合; 交叉验证集误差较大，我们如何判断是偏倚还是偏差呢？ 1 训练集误差和交叉验证集误差近似时： bias偏倚/低拟合; 2 交叉验证集误差远大于训练集误差时： variance偏差/过拟合 ; 归一化与偏倚/偏差一般会使用一些归一化方法来防止过拟合。但是我们可能会归一化的程度太高或太小了： 选择一系列的想要测试的$\lambda$ 值，通常是0-10之间的呈现2倍关系的值（如：0,0.01,0.02,0.04,0.08,0.15,0.32,0.64,1.28,2.56,5.12,10共12个）。选择$\lambda$ 的方法为： 1 使用训练集训练出12个不同程度归一化的模型; 2 用12个模型分别对交叉验证集计算的出交叉验证误差; 3 选择得出交叉验证误差最小的模型; 4 运用步骤3中选出模型对测试集计算得出推广误差; 也可以同时将训练集和交叉验证集模型的代价函数误差与$\lambda$ 的值绘制在一张图表上. 当$\lambda$ 较小时，训练集误差较小（过拟合） 而交叉验证集误差较大; 随着$\lambda$ 的增加，训练集误差不断增加（低拟合），而交叉验证集误差则是先减小后增加; 学习曲线（LEARNING CURVES） 学习曲线是将训练集误差和交叉验证集误差作为训练集实例数量（m）的函数绘制的图表。 当训练较少行数据的时候，训练的模型将能够非常完美地适应较少的训练数据，但是训练出来的模型却不能很好地适应交叉验证集数据或测试集数据。 用学习曲线识别低拟合/高偏倚 尝试用一条直线来适应下面的数据，可以看出，无论训练集有多么大误差还是很大： 说明： 欠拟合/high bias高偏倚 情况下， 训练集再大，也没有用 . 用学习曲线识别过拟合/高偏差 当交叉验证集误差远大于训练集误差时(过拟合): 往训练集增加更多数据可以提高模型的效果。 过拟合：拟合少部分数据，当训练集足够大时，能够更好的泛化数据。 总结解决过拟合-高偏差 1 获得更多的训练实例; 2 尝试减少特征的数量; 3 尝试增加归一化程度$\lambda$ ; 解决欠拟合-高偏倚 4 尝试获得更多的特征; 5 尝试更复杂的模型–如增加二项式特征; 6 尝试减少归一化程度$\lambda$ ; 神经网络的偏倚/偏差 使用较小的神经网络，类似于参数较少的情况，容易导致高偏倚/低拟合，但计算代价较小; 使用较大的神经网络，类似于参数较多的情况，容易导致高偏差/过拟合，虽然计算代价比较大，但是可以通过归一化手段来调整而更加适应数据。; 通常选择较大的神经网络并采用归一化处理会比采用较小的神经网络效果要好。; 对于神经网络中的隐藏层的层数的选择，通常从一层开始逐渐增加层数，为了更好地作选择，可以把数据分为训练集、交叉验证集和测试集，针对不同隐藏层层数的神经网络训练神经网络，然后选择交叉验证集代价最小的神经网络。]]></content>
      <categories>
        <category>吴恩达Coursera笔记</category>
      </categories>
      <tags>
        <tag>machine-learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8 正则化Regularization]]></title>
    <url>%2F2017%2F08%2F31%2Fregularization%2F</url>
    <content type="text"><![CDATA[正则化的目的就是把曲线拉得缓和些。 过拟合high variance我们可能有很多的特征，训练出来的模型和训练集拟合的也非常好，但对新数据的预测却不准，这有可以就是过拟合. - 上面分别是： 线性/欠拟合；二次/恰当；4次/过拟合- 但不是说用的4次就没有二次好，而是次数越多，θ 值会变得非常大以达到能拟合训练集的目的，曲线的震荡幅度也会非常大。- 我们需要曲线平滑些，需要一些regulated校准。### Logistic Rgression逻辑回归中的过拟合- 左图欠拟合：high bias: low polynomial- 中间quadratic fit- 右图 high polynomial 过拟合: high variance 如何应对过拟合？ 1 减少feature的数量：去除贡献少的features 可以手工选择，也可以使用Model selection algorithms，如PCA 2正则化regularization （有时也称penalty惩罚） 保留所有的特征，但是减少参数的取值范围（magnitude）：减少该参数对预测的贡献 更小的θ值减少了overfiting的可能 当有很多的features且都对最终结果有较多贡献时，这是个很好的减少过拟合的办法。 正则化代价函数（REGULARIZATION COST FUNCTION）以上面4次方回归为例： $$h_{\theta}(\boldsymbol{x}) = \theta_0 + \theta_1 x_1 + \theta_2 x_2^2 + \theta_3 x_3^3 +\theta_4 x_4^4$$ 要大大减少$\theta_3$和$\theta_4$的大小，我们要做的便是修改代价函数，在其中$\theta_3$和$\theta_4$设置一点惩罚。修改后的代价函数如下： 这样$\theta_3$和$\theta_4$ 的值会很小 (约等于零)，3次方和4次方对最后的结果影响也就小了，模型接近 二次方程 了。 对于非常多的特征，并不知道其中哪些特征我们要惩罚，那么就对所有的特征进行惩罚，得到了一个较为简单的能防止过拟合问题的假设： $\lambda$ 正则化参数（Regularization Parameter） 注意：根据惯例，我们不对θ0进行惩罚。 $\lambda$ 越大，惩罚越重 $\lambda$太大也不行，就欠拟合了： $\lambda=10^10$ ，除了$\theta_0$，其他的$\theta$都接近零了，这样hypothesis 就成了找最合适的一个水平线：$h_{\theta}(x) = \theta_0$：显然，欠拟合了。 $\lambda$ 有自动选择的算法，后面会讲。 正则化线性回归（REGULARIZED LINEAR REGRESSION） 正则化线性回归的代价函数为： 因为没有对$\theta_0$正则化，所以分开处理： 对于$j=1,2,…,n$ 时的更新式子 重写一下，看得更明白： 变化在于，每次都在原有算法更新规则的基础上令$\theta_j$值减少了一个额外的值（$\theta_j$的系数是一个常数，所以每次都要减小一点）：造成$\theta_j$变的更小，影响也就更小了。 也可以利用正规方程来求解正则化线性回归模型，方法如下所示 上式中的矩阵尺寸为$(n+1)\times (n+1)$。 正则化逻辑回归（REGULARIZED LOGISTIC REGRESSION）- 对于逻辑回归，我们也给代价函数增加一个正则化的表达式，得到： 类似，最小化该代价函数，求导，注意区分$\theta_0$： 得出梯度下降算法为： 看上去同线性回正则样，但是知道$h_{\theta}(x) = \sigma (\theta ^{\mathrm{\top}}\boldsymbol{X})$，所以与线性回归不同。]]></content>
      <categories>
        <category>吴恩达Coursera笔记</category>
      </categories>
      <tags>
        <tag>machine-learning</tag>
        <tag>regularization</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7 逻辑回归]]></title>
    <url>%2F2017%2F08%2F31%2Fsigmoid%2F</url>
    <content type="text"><![CDATA[前面我们将PGM经过转换，得到一种新的分类方法逻辑回归： 对应的Function set： 下面就是要获取最合适的$w,b$，还是使用最大似然估计：上面$(1-f_{w,b}(x^3))$表示$c2$类的概率。 我们在最大化似然估计前面加上负号，这样就转为了一个最优化问题。因为函数全是乘法，且sigmoid中有指数，我们开$ln$，整个函数表示成加法就简单了：问题就变为：$ argmin \sum -[\hat{y}lnf(x^i) + (1 - \hat{y}^i)ln(1 - f_{w,b}(x^n))]$ 。该公式另一种解释是两个Bernoulli分布的交叉熵： 交叉熵越小，说明分布越接近，也就是我们想得到的目标函数更接近训练集的分布。然后我们就是要优化这个公式，还是梯度下降：求出梯度，然后用学习率更新。$f$是一个sigmoid函数，有$\sigma (z)’ = \sigma (z)(1 - \sigma (z))$ , 这个导数很容易推出，我们看一下sigmoid函数图，就能发现，导数数在0点值最大，两边小： 梯度计算过程如下： 最后我们得到更新公式，和线性回归形式一样，但这里的y只能取1或者0。可以发现，与$\hat{y}$差别越大，step也就越大。 非线性边界对于下面的分类边界： 需要用曲线才能分隔 $y=0$的区域和$y=1$的区域，我们使用二次方程：$$f_{w,b}(\boldsymbol{x}) = \sigma (b + w_1 x_1 + w_2 x_2 +w_3 x_1^2 +w_4 x_2^2)$$ 假设参数是[-1 0 0 1 1]，则判定边界恰好是圆点在原点且半径为1的圆形。 还可以用更复杂的模型来适应非常复杂形状的判定边界:$$f_{w,b}(\boldsymbol{x}) = \sigma (b + w_1 x_1 + w_2 x_2 +w_3 x_1^2 +w_4 x_1^2x_2 + w_5 x_1^2x_2^2 + w_6x_1^3x_2 + …)$$ 如何选择这些模型？？：观察数据 Why not Square Error前面我们的评价函数是通过最大似然估计得到的，为什么不用线性回归中的square error呢？我们可以计算一下，得到square error的梯度： 发现，在当$\hat{y} ^ n= 1$时，$f = 1 OR 0$ 都会使得梯度等于0；$\hat{y} ^ n= 0$时也会出现这种情况。这样square error会很平坦，很难收敛。对比一下根据最大似然得到的交叉熵和square error两种cost function图，前者陡峭容易收敛，后面平坦，很难甚至无法收敛： 最后我们看一下线性回归和逻辑回归的对比： LR vs PGM逻辑回归和概率生成模型虽然都是来自同一个模型（function set相同），但是最终会选择不同的目标函数。 LR最后的w，b更多的是和训练集结合。 PGM包含统计信息更强烈，概率分布带来的额外”脑补“会使得这个模型可能做出一些不正确的判断； 一般认为LR准确率更高。 PGM更适合小训练集的情况，另外对noise容忍度高 多类与softmax多类的分类我们可以采用softmax分类，以三个类分类为例。我们为每个类使用$w,b$,得到每个分类的概率，有： 最后得到的不同z，用softmax归一化：先取指数，然后归一化得到概率： 训练方法类似二分类，最后得到一个3分布的交叉熵： Limitation of Logistic Regression像逻辑回归这类的线性模型没法区分出异或操作： 但是我们对$\boldsymbol{x}$做一个转换后，就能分了： 但是除非你有邻域知识能后帮助你找到这个转换，如异或例子。大多数非线性场景我们无法直接获得这种转换。怎么办？ 我们可以用LR交叠的方式先获取一个转换，然后在执行分类： 这就是神经网络了！]]></content>
      <categories>
        <category>吴恩达Coursera笔记</category>
      </categories>
      <tags>
        <tag>machine-learning</tag>
        <tag>Probabilistic-Generative-Model</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6 Probabilistic Generative Model概率生成模型]]></title>
    <url>%2F2017%2F08%2F31%2Fpgm%2F</url>
    <content type="text"><![CDATA[在介绍洛基回归模型之前，我们先了解以下概率生成模型。贝叶斯模型给了我们发现反向概率的方法： 对于一般的分类模型，我们也可以采用类似的方法，若果$P(C_1 | \boldsymbol{x}) &gt; 0.5$ ， $ \boldsymbol{x}$属于$C_1$，否则属于$C_2$。 上面的box，所有的概率分布都很清楚，可以直接得到最终的概率。但对于一个分类来说，我们要求$P(x|C_i)$就需要知道不同分类的概率分布。以一个Pockmon游戏中宠物分类的例子，取了两个类别水类（79个）和普通类（61个）的宠物，每个宠物有6个features。 对于训练集来说，$p(c_1), p(c_2)$是常数，统计一下就可以： 对于一般的分类模型，我们用features向量$\boldsymbol{x}$来表示一个物种。剩下的就是要求$P(\boldsymbol{x}|C_i)$：也就每一个分类中，一个未知$\boldsymbol{x}$在该类出现的概率／密度函数。我们目标是就是需要根据sample数据，得到不同分类的概率密度函数$P(\boldsymbol{x}|C_i)$。假设每个分类服从高斯分布： 我们就需要根据sample 数据得到均值$\mu$, 协方差矩阵covariance matrix $\Sigma$。很自然想到使用最大似然估计得到$\mu ^, \Sigma ^$：得到最接近sample数据的高斯分布。 我们根据最大似然估计，对水类和普通类得到对应的高斯分布（以两个features为例）：对于一个未知的物种$\boldsymbol{x}$,我们就可以得到他在不同类别中的概率，可以用前面的贝叶斯做分类了：最后在测试集的结果不太好，准确率只有47%，用上全部6个features的话，准确率是64%。### 模型改进前面两个分类的covariance matrix 是在各自分类中计算得到的，结果不同。现在把他们的covariance matrix 变成一个，目的是减少模型的偏差variance，也就是降低模型复杂度，减少overfitting。计算方法也很简单，就是将原来分类的$\Sigma ^i$做一个加权平均即可。再用新的参数来做分类，准确率提高到了73%！。可以看出，分类边界变成了线性边界,分类的模型也就变成了线性模型了，后面我们再看为什么变成了线性模型。总结一下，这种模型分为3步： 概率分布的选择前面我们使用的是多维高斯分布，当然你也可以使用其他的概率分布做，如下面用一维的高斯分布，假设所有的featutes之间独立，那么这就是朴素贝叶斯分类了： 后验概率和Sigmoid函数我们将上面的贝叶斯公式做一下转变： 我们看到，我们将后验概率表示成一个sigmoid函数，而$z$是$\boldsymbol{x}$在两个分类中概率比率的ln值，将出现概率的对比映射到(0,1) 之间，很明显： 当$\boldsymbol{x}$在两类出现的概率相同时，$z = 0$，就是sigmoid函数中间的点。 当$\boldsymbol{x}$在类1中概率更大时，$z &gt; 0$就是右侧。 当$\boldsymbol{x}$在类1中概率更小时，$z &lt; 0$就是左侧。 这样我们用sigmoid表示后验概率： 计算$z$的表达式： $z$看着挺复杂的，那么把上面的$\Sigma ^1, \Sigma ^2$按照前面的做法合一做进一步简化，可以更清晰的将$z$表示为一个一维函数了： (哇哇！！逻辑回归的味道来了！)这样经过一系列计算，我们将PGM模型转换为了基于sigmoid的线性模型（当然我们是简化合并了$\Sigma$），这就能解释上面的宠物分类在$\Sigma$合并后由曲线的分类边界变成了线性的分类边界了。]]></content>
      <categories>
        <category>吴恩达Coursera笔记</category>
      </categories>
      <tags>
        <tag>machine-learning</tag>
        <tag>Probabilistic-Generative-Model</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5 分类问题]]></title>
    <url>%2F2017%2F08%2F31%2Fclassification%2F</url>
    <content type="text"><![CDATA[这节，我们来看一下分类问题： 哪些邮件是垃圾邮件/正常邮件？ 我们先说二元分类： 因变量(dependant variable)可能属于的两个类： negative class 负向类 positive class 正向类 则因变量：$y \in {0,1}$,其中0表示负向类，1表示正向类。 分类问题建模线性回归建模 我们先尝试用线性回归的方法来建模： 取阈值为0.5，貌似预测的结果不错；但若训练集中有一个更大的数据(一个很靠右的训练点)，这样直线拟合的更趋缓一些： 那么我们再使用0.5做阈值就不行了。 这是因为线性回归模型预测的值可以超越[0,1]的范围，并不适合解决这样的问题。 所以我们引入一个新的模型： 逻辑回归，该模型的输出范围始终在0，1之间。]]></content>
      <categories>
        <category>吴恩达Coursera笔记</category>
      </categories>
      <tags>
        <tag>machine-learning</tag>
        <tag>classification</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4 多项式回归]]></title>
    <url>%2F2017%2F08%2F31%2FpolynomialRegression%2F</url>
    <content type="text"><![CDATA[前面提到的线性回归，但实际上很多问题是不能用一根直线来区分的。有时需要曲线来拟合我们的数据，那么这是我们就可以考虑多项式回归。比如一个二次方模型quadratic model：$$h_{\theta}(x) = \theta_0 + \theta_1 x + \theta_2 x^2 $$ 或 三次方模型 cube function：$$h_{\theta}(x) = \theta_0 + \theta_1 x + \theta_2 x^2 + \theta_3 x^3 $$ 拟合效果如下： 上例中，只有一个feature即size，对该参数实行多项式计算；注意，quadratic model最后会下行，而cube function 最后会上行。 其实还可以用另一个模型，拟合的更好： $h_{\theta}(x) = \theta_0 + \theta_1 x + \theta_2 x^{\frac{1}{2}} $. 通常我们要观察数据( 图形是一个直观的观察方式 )，然后才能决定用什么样的模型。 这里面也要考虑特征feature的选择:洞察问题，选择最佳的features。 有时还需要对特征进行组合：若原始feature是房屋的长，宽，这显然不是很好的特征，把他们组合新生成一个特征：面积。 注意：我们采用多项式回归模型，在运行梯度下降算法前，特征缩放非常有必要。 正规方程normal equation 某些情况，能够直接求解”最佳”$\theta$ 前面我们一直用梯度下降法找到使cost function 最小化的参数。 对于线性回归等(凸问题，存在全局最优解)，用正规方程normal equation能直接得出答案，即直接求解导数为0的值下式：$$\frac{\partial}{\partial \theta_j} J(\theta_j) = 0$$ 对于训练集特征矩阵为$\boldsymbol{X}$（包含了$\boldsymbol{x}_0=1$）， 得到的解向量为:$$\theta = (\boldsymbol{X}^{\mathrm{\top}} \times \boldsymbol{X})^{-1} \times \boldsymbol{X}^{\mathrm{\top}} \times \boldsymbol{y}$$ 对于不可逆矩阵(如feature间相关，或者特征数大于训练集数等)，正规方程不能用。 梯度下降与正规方程的比较：]]></content>
      <categories>
        <category>吴恩达Coursera笔记</category>
      </categories>
      <tags>
        <tag>machine-learning</tag>
        <tag>linear-regression</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3 多变量线性回归]]></title>
    <url>%2F2017%2F08%2F30%2FlinearRegressionWithMultiVariable%2F</url>
    <content type="text"><![CDATA[实际应用场景中一般都是多个features特征，例如房间数，楼层等，构成一个多变量的模型，模型中的特征为$（x_1,x_2,…,x_n）$： $n$ 特征的数量 $\boldsymbol{x}^{(i)}$ 第$i$个训练实例，是特征矩阵中的第$i$行，是一个向量（vector）。 $x^{(i)}_j $ 第$i$个训练实例的第$j$个特征，即特征矩阵中第$i$行的第$j$个特征。 多变量线性回归 支持多变量的假设$h$ 为：$$h_{\theta}(x) = \theta_0 + \theta_1 x_1 \theta_2 x_2 + … + \theta_n x_n$$ 有 $n+1$ 个参数和$ n$ 个变量，为了方便处理，引入$x_0 = 1$，公式转换为: $$h_{\theta}(x) = \theta_0 x_0 + \theta_1 x_1 \theta_2 x_2 + … + \theta_n x_n$$ 这样，参数 $n+1$ 维的向量，训练实例也是一个$n+1$ 维向量，我们就可以直接用矩阵操作了。 特征矩阵(训练实例) 维度是 $m×(n+1)$, 公式也就简化为： $$h_{\theta} (\boldsymbol{X}) = \theta ^\mathrm{\top} \boldsymbol{X}$$ 多变量梯度下降gradient Descent for multiple variables与单变量梯度下降相似，构造损失函数： $$J(\theta_0 , \theta_1 ,…,\theta_n) = \frac{1}{2m} \sum^m_{i=1}(h_{\theta} (x^{(i)}) - y^{(i)})^2$$ 对$\theta_i$的参数求导，批量梯度下降，直到收敛： 求导后，代入： 计算过程是先随机选取一系列参数值，然后计算预测结果，代入上式，更新参数值，直到参数收敛。这里会遇到一些问题，一个是不同参数的尺度问题，还有的学习率问题，下面的2个tricks可以帮助解决这些问题： 特征缩放 Feature Scaling以上面的房价预测为例，房间数为0-5，尺寸是0-2000平方英尺，这样画出来的等高线是一个很长的椭圆，需要很多次迭代才能收敛： 为了使收敛速度更快（另外不同的数据级在其他的算法中可能需要一起操作，大级别的参数会覆盖小级别参数的变化），我们要保证这些特征具有相似的尺度similar scale，可以帮助梯度更快的收敛： 解决的方法是尝试将参数的范围放大[-1, 1]间，最简单的方法是：$$x_n=\frac{x_n - \mu_n}{S_n}$$ 其中 $\mu_n$ 是平均值，$S_n$是 标准差。 简单的说就是这个：$$x^*_i=\frac{x_i - \bar{x}}{x_{max} - x_{min}}$$ 特征缩放也称为： Normalization 归一化 学习率learning rate 收敛所需要的迭代次数根据模型不同而不同，可以用迭代次数与代价函数的图标来感官的查看： 代价函数应该在每次迭代后都应该有所减少，直到收敛，上图最后的浅蓝部分就收敛的不错了。 学习率过小，迭代次数太多，学习率太大，可能会错过局部最小值，通常考虑下面的学习率： 0.01，0.03，0.1，0.3，1，3， 10]]></content>
      <categories>
        <category>吴恩达Coursera笔记</category>
      </categories>
      <tags>
        <tag>machine-learning</tag>
        <tag>linear-regression</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2 单变量线性回归]]></title>
    <url>%2F2017%2F08%2F30%2FlinearRegressionWithOneVariable%2F</url>
    <content type="text"><![CDATA[单变量线性回归 linear regression with one variable房价预测： 问题描述： $m $ 代表训练集中实例的数量 $x $ 代表特征/输入变量 $y $ 代表目标变量/输出变量 $(\boldsymbol{x,y}) $ 代表训练集中的实例 $ (x^{(i)},y^{(i)}) $ 代表第i个观察实例 $h $ 代表学习算法的解决方案或函数也称为假设（hypothesis）: 由训练集通过学习算法，学习得到一个假设$h$（这个假设就是一个模型），新的数据通过h，预测出房价。 如何表达$h$？这个例子中，我们先用一个线性方程：$$h_{\theta}=\theta_0 + \theta_1 x$$ 因为只含有一个特征/输入变量，因此这样的问题叫作单变量线性回归问题. 线性关系（Linearity）是变量与自变量成一次方的函数关系。其画在函数图上会呈现一条直线。 代价函数cost function 确定了$h$的形式，我们就要为模型选择合适的参数parameters ： $\theta_0, \theta_1$。 预测值与实际值的差距就是建模误差modeling error 我们选择的建模误差的平方和( square error function)作为模型的代价函数，目标就是选择使得代价函数最小的模型参数。 总结 Hypothesis： $h_{\theta}=\theta_0 + \theta_1 x$ Parameters: $\theta_0, \theta_1$ Cost function: 其中$m$为样本个数 Goal : 最小化代价函数 下面的等高图，三个坐标分别为 $\theta_0, \theta_1, J(\theta_0, \theta_1)$：我们就是要找到那个凹点，使得$ J(\theta_0, \theta_1)$值最小。 如何找？下面介绍一种方法来求解代价函数的最小值。 梯度下降Gradient descent 思想：初始化参数（随机找一个参数组合 $\theta_0, \theta_1, … \theta_n$, 目标是寻找下一个能让代价函数值下降最多的参数组合，持续这么做直到一个局部最小值（local minimum）。 因为没有试过所有的参数组合，所以不能确认局部最小值是否是全局最小值（global minimum） 选择不同的初始参数组合，可能会找到不同的局部最小值。下图显示使用不同的初始值到达的不同的local minimum： Gradient descent algorithm 沿下降最快的方向（导数）梯度下降(参数必须同步更新)，下降率由learning Rate控制： 下降速度最快的方向为什么是导数方向：直观的例子，在一个下坡路，找一条离坡地最近的路：当然是沿着坡道直下（导数方向）而不是走Z字行下：上坡为省力选择Z字小坡度上，但是距离也更长；上图也可以想象为一个山脉，你想找到一条离山谷最近的路，当然是走最陡峭的路最近（这是一种贪婪算法，不一定是最优），最陡峭也就是导数方向(曲面的导数）。 为什么是减去？下图分为了左右两部分下降：左边部分因为导数是负数，减的话就成加了： 这样每个参数都是在它的导数即下降最快的方向下降。 学习率 α 太小，学习太慢 太大，可能错过最优点：fail to converge or even diverge 即使固定α，因为随着导数变小，后面的step也会逐渐变小的，所以也能够converge： 收敛的标准 最好当然是变化为0 $J(\boldsymbol{\theta}) 变化不超过过1/1000,我们就认为converge了 批量梯度下降（batch gradient descent） batch： 每次都用到所有的training data对于前面的线性回归问题，运用batch gradient descent方法，关键是求出代价函数的导数，首先回顾一下模型： 计算两个参数的倒数： 这样我们将梯度下降公式做一下替换： References 吴恩达，《Machine learning》，Coursera.]]></content>
      <categories>
        <category>吴恩达Coursera笔记</category>
      </categories>
      <tags>
        <tag>machine-learning</tag>
        <tag>gradient-descent</tag>
        <tag>linear-regression</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1 机器学习概述]]></title>
    <url>%2F2017%2F08%2F30%2FmachineLearning%2F</url>
    <content type="text"><![CDATA[机器学习: 从数据中学到知识。 Computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P improves with experience E. from Tom Mitchell,1998. T: 任务； P: performance measure E: experience经验，实验 基于E的不断学习，通过P的指标得出在T上的表现得到改进，我们就说程序通过经验E来学习该任务。 如预计房价： 最简单的方法就是用一根直线(也就是一次方程)来预测，用二次函数能够得到更好的结果： 这种学习称为 监督学习 supervised learning: 预先有正确的结果，可以用来指导，检验算法的正确性。 监督学习 supervised learning 1 回归regression ： 连续值预测 2 分类classification： 离散值预测，如何根据特征将对象分到不同的分类中(赋予不同的离散值) - 上面的例子只用到两个特征 features，更多的特征处理可能需要其他算法，如SVM。 非监督学习 unsupervised learning 特点：训练数据只有特征，没有结果：发现这些数据是否可以分为不同的组,应用包括： 聚类问题Clustering 声音辨别：将不同人的声音分离，使用双麦克，位置的远近，角度会造成声音的大小等不同。使用svd一行代码就能解决。 References 吴恩达，《Machine learning》，Coursera.]]></content>
      <categories>
        <category>吴恩达Coursera笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[为什么梯度反方向下降最快？]]></title>
    <url>%2F2017%2F08%2F20%2FwhyDescent%2F</url>
    <content type="text"><![CDATA[梯度下降算法中，为什么沿着梯度反方向是下降最快呢？用一种直观的方法”证明”一下。考虑两个features的情况。首先用泰勒一阶展开，问题转换为在点(a,b)附近（我们可以限制在以点为圆心的圆内）哪个方向可以使得函数值最小？ 转换成一个更好理解的公式：看一下公式的后两项，就是两个向量的点积，$[u,v]^ \top$是已知的，要使点积值最小（这里负值是最小的了），当然是和$[u,v]^ \top$方向相反，并且尽可能远的向量了： 参考 李宏毅，《machine learning》]]></content>
      <categories>
        <category>machine-learning</category>
      </categories>
      <tags>
        <tag>梯度下降</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数值计算需要注意的问题]]></title>
    <url>%2F2017%2F08%2F19%2FnumCalculate01%2F</url>
    <content type="text"><![CDATA[数值计算中，需要考虑计算机精度带来的一些问题。 Overflow and Underflow上溢和下溢数字计算机无法对实数进行”精确”表示,总会引入些误差（大部分是舍入误差rounding errors）。当这些误差被复合累积操作时，会造成一些问题。 误差的下溢 ： 接近零的的数被四舍五入为零。很多时候等于零与接近零的表现质的不同。上溢：当大量级的数被近似为$\infty, -\infty$,进一步计算会导致非数字。例如softmax函数，经常用于预测与multinoulli 分布相关联的概率，定义为： 考虑所有$x$都等于$c$，那么softmax的理论值为$\frac{1}{n}$。但是在数值计算中，当$c$量级很大时，可能求不到： If $c$ is very negative, $\exp (c)$会underflow：造成分母为0。 $c$是一个很大数，造成$\exp (c)$overflow； 我们可以通过计算$\mathrm{softmax} (\boldsymbol{z})$来避免这些问题，其中 $\boldsymbol{z = x} - \max _i x_i$ : 减去$\max _i x_i$导致exp最大参数为0；不会overflow； 同样的原因，分布至少有一个值为1，排除分母underflow变成被0除的可能。 另外分子的underflow可导致整体结果为零。若在计算$log (softmax(x))$ 函数中，先计算softmax，再代入计算log有可能出现负无穷结果。所以我们要实现一个单独的函数以数值稳定的方式来计算。 所以计算时一定要考虑数值不稳定的问题，必须设计为最小化舍入误差的积累。 病态条件数Poor Conditioning条件数conditioning是指函数相对于输入的微小变化而变化的快慢程度，而迅速变化的函数是不理想的：舍入误差会造成很大的变化。 考虑函数$f(x) = A^{-1} x$, 当$A \in \mathbb{R}^{n \times n}$具有特征分解时，其条件数为：$$\underset{i,j}{\max}~ \Bigg| \frac{\lambda_i}{ \lambda_j} \Bigg|.$$这是最大和最小特征值的模之比,当该数很大时，矩阵求逆对输入的误差特别敏感。注意这种敏感性是矩阵本身的固有特性，而不是矩阵求逆期间舍入误差的结果。 即使我们乘以完全正确的矩阵逆，病态条件的矩阵也会放大预先存在的误差。 在实践中，该错误将与求逆过程本身的数值误差进一步复合。]]></content>
      <categories>
        <category>math</category>
      </categories>
      <tags>
        <tag>数值计算</tag>
        <tag>overflow &amp; underflow</tag>
        <tag>poor conditioning</tag>
      </tags>
  </entry>
</search>
